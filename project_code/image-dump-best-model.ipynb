{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-22T16:35:55.159306Z",
     "start_time": "2025-05-22T16:35:50.464613Z"
    }
   },
   "source": [
    "from pathlib import Path\n",
    "from cub_dataset import CUBDataset\n",
    "from image_transform import get_image_transform, get_inv_image_transform\n",
    "import torch\n",
    "image_root = Path(\"C:\\\\Users\\\\Matej\\\\Documents\\\\CUB\\\\images\")\n",
    "captions_root = Path(\"C:\\\\Users\\\\Matej\\\\Documents\\\\CUB\\\\captions\")\n",
    "embeddings_root = Path(\"C:\\\\Users\\\\Matej\\\\Documents\\\\CUB\\\\embeddings\")\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "l1_coef = 50\n",
    "l2_coef=100\n",
    "\n",
    "test_set = CUBDataset(\n",
    "        image_root=image_root,\n",
    "        embeddings_root=embeddings_root,\n",
    "        image_transform=get_image_transform(64),\n",
    "        device=device,\n",
    "        seed=1234,\n",
    "        split=(0.8, 0.0, 0.2),\n",
    "        subset=\"train\",\n",
    "    )"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matej\\Documents\\seminar2\\text-to-image\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading train set: 200it [00:00, 2113.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 9430 samples for train subset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T16:36:08.844832Z",
     "start_time": "2025-05-22T16:36:08.623123Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch import nn\n",
    "from DCGAN import Generator, Discriminator\n",
    "\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "best_model_path = \"C:\\\\Users\\\\Matej\\\\Documents\\\\seminar2\\\\trained_models\\\\train1-for-testing\\\\saved_models\\\\ep200.tar\"\n",
    "\n",
    "checkpoint = torch.load(best_model_path, map_location=device)\n",
    "generator.load_state_dict(checkpoint['generator'])\n",
    "discriminator.load_state_dict(checkpoint['discriminator'])\n",
    "\n",
    "generator.eval()\n",
    "discriminator.eval()\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "l2_loss = nn.MSELoss()\n",
    "l1_loss = nn.L1Loss()\n",
    "\n",
    "generator.to(device)\n",
    "discriminator.to(device)\n",
    "criterion.to(device)\n",
    "\n",
    "def get_loss(images, embeddings):\n",
    "    noise = torch.randn(1, 100).to(device)\n",
    "    fake_images = generator(embeddings, noise)\n",
    "    out_fake, act_fake = discriminator(fake_images, embeddings)\n",
    "    out_real, act_real = discriminator(images, embeddings)\n",
    "    g_bce = criterion(out_fake, torch.full_like(out_fake, 1))\n",
    "    g_l1 = l1_coef * l1_loss(fake_images, images)\n",
    "    g_l2 = l2_coef * l2_loss(torch.mean(act_fake, 0), torch.mean(act_real, 0).detach())\n",
    "    g_loss = g_bce + g_l1 + g_l2\n",
    "    return g_loss, fake_images"
   ],
   "id": "2a64e1e839b65311",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T16:36:13.919231Z",
     "start_time": "2025-05-22T16:36:13.905580Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from PIL import Image\n",
    "\n",
    "def combine_images_64_to_128(image1, image2):\n",
    "    # Resize both images to 128x128\n",
    "    image1 = image1.resize((128, 128), Image.Resampling.LANCZOS)\n",
    "    image2 = image2.resize((128, 128), Image.Resampling.LANCZOS)\n",
    "\n",
    "    # Create a new image with combined width and common height\n",
    "    combined = Image.new(\"RGB\", (image1.width + image2.width, 128))\n",
    "\n",
    "    # Paste images side by side\n",
    "    combined.paste(image1, (0, 0))\n",
    "    combined.paste(image2, (image1.width, 0))\n",
    "\n",
    "    return combined\n"
   ],
   "id": "18faf1f82eeb3f0c",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T16:47:17.956776Z",
     "start_time": "2025-05-22T16:36:16.276781Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "output_path = Path(\"C:\\\\Users\\\\Matej\\\\Documents\\\\seminar2\\\\trained_models\\\\best-model-dump\")\n",
    "\n",
    "losses = {\n",
    "\n",
    "}\n",
    "\n",
    "for i, sample_path in tqdm(enumerate(test_set.sample_paths)):\n",
    "    # print(sample_path)\n",
    "    image_path = image_root / f\"{sample_path}.jpg\"\n",
    "    embeddings_path = embeddings_root / f\"{sample_path}.pt\"\n",
    "    captions_path = captions_root / f\"{sample_path}.txt\"\n",
    "\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = get_image_transform()(image)\n",
    "    image = image.unsqueeze(0)\n",
    "    image = image.to(device)\n",
    "\n",
    "    embedding = torch.load(embeddings_path, map_location=device)\n",
    "    embedding = embedding.unsqueeze(0)\n",
    "    embedding = embedding.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        loss, gen_img_tensor = get_loss(image, embedding)\n",
    "        losses[i] = loss.item()\n",
    "\n",
    "    with open(captions_path, \"r\") as f:\n",
    "        caption = f.read()\n",
    "\n",
    "    save_path = output_path / str(i)\n",
    "    save_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    real_image = get_inv_image_transform()(image[0])\n",
    "    fake_image = get_inv_image_transform()(gen_img_tensor[0])\n",
    "\n",
    "    combined_image = combine_images_64_to_128(real_image, fake_image)\n",
    "    combined_image.save(str(save_path / f\"{Path(sample_path).name}.png\"))\n",
    "\n",
    "    #real_image.save(str(save_path / f\"{Path(sample_path).name}_real.png\"))\n",
    "    #fake_image.save(str(save_path / f\"{Path(sample_path).name}_fake.png\"))\n",
    "    with open(str(save_path / \"caption.txt\"), \"w\") as f:\n",
    "        f.write(caption + f\"\\nloss: {loss.item()}\")\n",
    "\n"
   ],
   "id": "ab1cac2800ef1ad0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9430it [11:01, 14.25it/s]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T16:47:25.044803Z",
     "start_time": "2025-05-22T16:47:25.033510Z"
    }
   },
   "cell_type": "code",
   "source": [
    "items = losses.items()\n",
    "n_items = len(items)\n",
    "items = sorted(items, key=lambda x: x[1], reverse=False)\n",
    "print(items[0:10])"
   ],
   "id": "9cd2ca054e418888",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(4923, 9.635774612426758), (149, 9.672496795654297), (6147, 10.73388385772705), (7064, 10.751594543457031), (6092, 11.36527156829834), (5061, 11.496672630310059), (5905, 11.753509521484375), (9374, 11.839312553405762), (6532, 11.86898422241211), (6676, 11.886252403259277)]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T16:47:27.947508Z",
     "start_time": "2025-05-22T16:47:27.932565Z"
    }
   },
   "cell_type": "code",
   "source": "print(items[-9::])",
   "id": "8db98e87e8933ff5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(4736, 295.9927673339844), (6168, 301.3152770996094), (3209, 313.6275634765625), (8780, 339.16912841796875), (7468, 345.36590576171875), (4090, 397.13848876953125), (5333, 409.37713623046875), (3143, 452.7203063964844), (4674, 459.7781982421875)]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T23:03:47.136464Z",
     "start_time": "2025-05-21T23:03:47.079956Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from DCGAN import Generator, Discriminator\n",
    "print(Generator())"
   ],
   "id": "617d7d2b357c92d8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (projection): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=128, bias=True)\n",
      "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (main): Sequential(\n",
      "    (0): ConvTranspose2d(228, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (13): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T23:03:52.517704Z",
     "start_time": "2025-05-21T23:03:52.496088Z"
    }
   },
   "cell_type": "code",
   "source": "print(Discriminator())",
   "id": "624093a8ab545850",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (main): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (projection): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=128, bias=True)\n",
      "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (output): Sequential(\n",
      "    (0): Conv2d(640, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (1): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "31ae3100f60b04fa"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
